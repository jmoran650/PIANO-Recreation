// goalPlanAppServer.ts
import dotenv from 'dotenv';
import express, { Request, Response } from 'express';
import fs from 'fs';
import http from 'http';
import path from 'path';
import { Server as SocketIOServer } from 'socket.io';
import { generateAcronym } from './utils/acronyms';

dotenv.config();
// Remove direct main import from index if logic moved here
// import { main } from "./index"; // No longer needed if main logic is here
import { Worker } from 'worker_threads';
import { BotOptions } from './src/createAgentBot'; // Import BotOptions type
import {
  callLLMJsonSchema,
  getLLMMetrics,
  setLLMLogger,
  toggleLLMEnabled,
} from './utils/llmWrapper'; // Import LLM utils for main thread use

import OpenAI from 'openai'; // Import OpenAI for main thread proxy calls

const LOGFILE_PATH_PREFIX = path.join(__dirname, '../'); // Log path prefix

// Ensure log directory exists (optional)
// if (!fs.existsSync(LOGFILE_PATH_PREFIX)) {
//     fs.mkdirSync(LOGFILE_PATH_PREFIX);
// }

const app = express();
const server = http.createServer(app);
const io = new SocketIOServer(server);

if (process.env.MC_HOST == undefined) {
  throw new Error('MC_HOST not loaded');
}

if (process.env.MC_PORT == undefined) {
  throw new Error('MC_PORT not loaded');
}

// --- Centralized State and Worker Management ---
const workers = new Map<string, Worker>(); // Map username -> Worker
const botStates = new Map<string, any>(); // Map username -> latest serialized state
const botLogs = new Map<string, any[]>(); // Map username -> conversation log entries


const botOptionsList: BotOptions[] = [
  {
    host: process.env.MC_HOST, // Use env var or default
    port: parseInt(process.env.MC_PORT, 10),
    username: 'AgentBot',
    version: process.env.MINECRAFT_VERSION,
  },
  {
    host: process.env.MC_HOST,
    port: parseInt(process.env.MC_PORT, 10),
    username: 'DaBiggestBird',
    version: process.env.MINECRAFT_VERSION,
  },
];
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY }); // OpenAI instance for main thread proxy

// Setup LLM Logger (using console for simplicity, adapt as needed)
setLLMLogger((type, message, meta) => {
  console.log(`[LLMLog-${type}] ${message}`, meta ? JSON.stringify(meta) : '');
  // Could also emit this via socket.io if needed
});

// --- Worker Initialization ---
// --- Worker Initialization ---
function initializeWorkers() {
  console.log('Initializing workers...');

  const acronymMap = new Map<string, string>(); // To detect duplicates
  const validatedBotOptions: BotOptions[] = []; // Store options with acronyms after validation

  // --- Step 1: Generate Acronyms and Validate ---
  console.log('[Main] Generating and validating bot acronyms...');
  for (const options of botOptionsList) {
    if (!options.username) {
      console.error('Bot username is missing in options:', options);
      // Skip this bot configuration if username is missing
      continue;
    }
    const workerUsername = options.username;
    let acronym: string;

    try {
      acronym = generateAcronym(workerUsername); // Generate acronym using the helper
      if (!acronym) {
         // Handle cases where no capitals are found if needed, or let it be an empty string
         console.warn(`[Main] No capital letters found in username '${workerUsername}'. Acronym will be empty.`);
         // Depending on requirements, you might want to throw an error here instead:
         // throw new Error(`Could not generate acronym for '${workerUsername}' (no capital letters).`);
      }
    } catch (error: any) {
      // Handle unexpected errors from generateAcronym
      console.error(
        `[Main] Failed to generate acronym for '${workerUsername}': ${error.message}`
      );
      // Stop server initialization if acronym generation fails critically
      throw new Error(
        `Acronym generation failed for bot '${workerUsername}'. Server startup aborted.`
      );
    }

    // --- Conflict Check: Reserved "all" ---
    if (acronym.toLowerCase() === 'all') {
      throw new Error(
          `[Main] Acronym conflict! Bot '${workerUsername}' generates the reserved acronym 'all'. Please change the username.`
      );
    }

    // --- Conflict Check: Duplicates ---
    if (acronym && acronymMap.has(acronym)) { // Check only if acronym is not empty
      const existingBot = acronymMap.get(acronym);
      // Throw an error if duplicate is found
      throw new Error(
        `[Main] Duplicate acronym detected! Acronym '${acronym}' is generated by both '${existingBot}' and '${workerUsername}'. Please ensure bot usernames produce unique acronyms based on capital letters.`
      );
    }

    // Store valid acronym and add options to the list for worker creation
    if (acronym) { // Store only if acronym is not empty
        acronymMap.set(acronym, workerUsername);
    }
    console.log(
      `[Main] Acronym '${acronym || '(empty)'}' validated for bot '${workerUsername}'.`
    );
    validatedBotOptions.push({ ...options, acronym }); // Add acronym to options
  }
  console.log('[Main] Acronym validation complete.');

  // --- Step 2: Create Workers with Validated Options ---
  console.log('[Main] Creating worker threads...');
  validatedBotOptions.forEach((optionsWithAcronym) => {
    const workerUsername = optionsWithAcronym.username; // Get username from the validated options
     if (!workerUsername) return; // Should not happen if validated correctly, but safe check

    console.log(`Creating worker for ${workerUsername} with acronym '${optionsWithAcronym.acronym || '(empty)'}'...`);
    const worker = new Worker(path.resolve(__dirname, 'src/botWorker.js'), {
      workerData: optionsWithAcronym, // Pass options WITH the acronym
    });

    workers.set(workerUsername, worker);
    botStates.set(workerUsername, {}); // Initialize state
    botLogs.set(workerUsername, []); // Initialize logs

    // --- Worker Event Listeners (Copied and adjusted from original) ---
    worker.on('message', (message: any) => {
      // Make sure message.payload.username exists where needed
      const msgUsername = message.payload?.username;

      switch (message.type) {
        case 'initialized':
          if (msgUsername) {
             console.log(
               `[Main] Worker ${msgUsername} initialized successfully.`
             );
             worker.postMessage({ type: 'getState' });
           } else {
             console.warn('[Main] Received \'initialized\' message without username.');
           }
          break;
        case 'stateUpdate':
          if (msgUsername) {
             botStates.set(msgUsername, message.payload.state);
             // Update logs based on state if conversationLog exists
             if (message.payload.state?.conversationLog) {
               botLogs.set(
                 msgUsername,
                 message.payload.state.conversationLog
               );
             }
           } else {
             console.warn('[Main] Received \'stateUpdate\' message without username.');
           }
          break;
        case 'logEntry':
          const logUsername = msgUsername;
          if (logUsername) {
              const entry = message.payload.entry;
              const currentLogs = botLogs.get(logUsername) || [];
              currentLogs.push(entry);
              botLogs.set(logUsername, currentLogs);
              // Optional: Append to file immediately (consider performance for high volume)
              try {
                  const logFilePath = `${LOGFILE_PATH_PREFIX}${logUsername}_conversation.log`;
                  fs.appendFileSync(
                      logFilePath,
                      JSON.stringify(entry) + '\n',
                      'utf8'
                  );
              } catch (e) {
                  console.error(`[Main] Error writing log for ${logUsername}:`, e);
              }
          } else {
             console.warn('[Main] Received \'logEntry\' message without username.');
          }
          break;
        case 'llmRequest':
          // Assuming payload structure includes botUsername for LLM requests
          console.log(
            `[Main] Handling LLM Request ${message.requestId} from ${message.payload?.botUsername || 'unknown worker'}`
          );
          handleProxiedLLMRequest(worker, message.requestId, message.payload); // Ensure handleProxiedLLMRequest gets worker context if needed
          break;
        case 'goalPlanProgress':
        case 'goalPlanComplete':
        case 'goalPlanError':
           if (msgUsername) {
                console.log(
                    `[Main] Forwarding goal plan update type ${message.type} from ${msgUsername}`
                );
                // Emit with username for potentially targeted UI updates
                io.emit(message.type, {
                    username: msgUsername,
                    data: message.payload.tree || message.payload.error
                });
            } else {
                console.warn(`[Main] Received '${message.type}' message without username.`);
                // Fallback: emit without username
                io.emit(message.type, message.payload.tree || message.payload.error);
            }
          break;
        case 'botError':
        case 'botKicked':
        case 'botEnd':
        case 'initializationError':
          console.error(
            `[Main] Critical event from worker ${msgUsername || 'unknown'}: ${message.type}`,
            message.payload
          );
          // Consider removing worker from 'workers' map here if it's a fatal error
          break;
        default:
          console.warn(
            `[Main] Received unknown message type from ${workerUsername}: ${message.type}`
          );
      }
    });

    worker.on('error', (err) => {
      console.error(`[Main] Worker ${workerUsername} error:`, err);
      workers.delete(workerUsername);
      botStates.delete(workerUsername); // Clean up state on error
      botLogs.delete(workerUsername);   // Clean up logs on error
    });

    worker.on('exit', (code) => {
      console.log(`[Main] Worker ${workerUsername} exited with code ${code}`);
      workers.delete(workerUsername);
      botStates.delete(workerUsername); // Clean up state on exit
      botLogs.delete(workerUsername);   // Clean up logs on exit
      if (code !== 0) {
        console.error(`[Main] Worker ${workerUsername} exited abnormally!`);
        // Consider restart logic here if desired
      }
    });
  });
  console.log('[Main] Worker creation loop finished.');
}


// --- LLM Proxy Handler ---
async function handleProxiedLLMRequest(
  worker: Worker,
  requestId: string,
  payload: any
) {
  const { type, data } = payload;
  let responsePayload: any;
  try {
    // Log the request received by main thread proxy
    console.log(`[Main LLM Proxy] Request ${requestId} - Type: ${type}`);
    // Optionally log full payload if needed: console.log(JSON.stringify(data));

    if (type === 'chat') {
      // Assuming data = { model?, messages, tools?, tool_choice?, parallel_tool_calls? }
      // Call the actual OpenAI API using the main thread's instance/wrapper
      const completion = await openai.chat.completions.create({
        model: data.model || 'gpt-4o', // Use provided or default
        messages: data.messages,
        tools: data.tools,
        tool_choice: data.tool_choice,
        parallel_tool_calls: data.parallel_tool_calls,
      });
      responsePayload = { response: completion }; // Send back the full completion object structure
      console.log(`[Main LLM Proxy] Response ${requestId} - Success (Chat)`);
    } else if (type === 'json') {
      // Assuming data = { model?, systemMsg, userMsg, jsonSchema }
      // Use callLLMJsonSchema directly in main thread
      const result = await callLLMJsonSchema(
        data.systemMsg,
        data.userMsg,
        data.jsonSchema
      );
      responsePayload = { response: result.parsed }; // Send back only the parsed object
      console.log(`[Main LLM Proxy] Response ${requestId} - Success (JSON)`);
    }
    // Add 'tools' type if FunctionCaller uses a different proxy path
    else {
      throw new Error(`Unsupported LLM proxy type: ${type}`);
    }
  } catch (error: any) {
    console.error(
      `[Main LLM Proxy] Error processing request ${requestId}:`,
      error
    );
    responsePayload = { error: error.message || String(error) };
  }

  // Send response back to the worker
  worker.postMessage({
    type: 'llmResponse',
    requestId,
    payload: responsePayload,
  });
}

// --- Express & Socket.IO Setup ---
app.use(express.static(path.join(__dirname, '../public')));

app.get('/', (req: Request, res: Response) => {
  res.sendFile(path.join(__dirname, '../public/index.html'));
});

app.get('/goal-planner', (req: Request, res: Response) => {
  res.sendFile(path.join(__dirname, '../public/index.html'));
});

app.post('/toggle-llm', (req: Request, res: Response) => {
  const newState = toggleLLMEnabled();
  const message = newState ? 'LLM requests enabled.' : 'LLM requests disabled.';
  res.json({ message: message, enabled: newState });
});

io.on('connection', (socket) => {
  console.log('Browser connected via Socket.IO:', socket.id);

  // Send initial state immediately if available
  if (botStates.size > 0) {
    const allCurrentStates: Record<string, any> = {};
    botStates.forEach((state, username) => {
      allCurrentStates[username] = {
        ...state,
        conversationLog: botLogs.get(username) || [],
      }; // Combine state + log
    });
    socket.emit('allSharedStates', allCurrentStates);
  }

  // Setup interval for sending state updates to this specific client
  const intervalId = setInterval(() => {
    try {
      const allCurrentStates: Record<string, any> = {};
      // Construct state object for emission, combining latest state and logs
      workers.forEach((_, username) => {
        const state = botStates.get(username) || {};
        const logs = botLogs.get(username) || [];
        allCurrentStates[username] = { ...state, conversationLog: logs }; // Send combined data
        // Add LLM metrics (assuming they are global in main thread)
        allCurrentStates[username].llmMetrics = getLLMMetrics();
      });
      socket.emit('allSharedStates', allCurrentStates);
    } catch (error) {
      console.error('[Main] Error in server state update interval:', error);
    }
  }, 1000); // Update interval

  socket.on('disconnect', () => {
    clearInterval(intervalId);
    console.log('Browser disconnected:', socket.id);
  });

  // Handle goal planning requests from this client
  socket.on(
    'startGoalPlan',
    async (data: { goal: string; mode?: 'bfs' | 'dfs' }) => {
      try {
        const goal = data.goal;
        const mode = data.mode || 'bfs'; // Default to bfs
        // Determine which bot should handle (e.g., AgentBot)
        const targetWorker = workers.get('AgentBot'); // Example: hardcode AgentBot
        if (!targetWorker) {
          throw new Error('Target bot worker (AgentBot) not found.');
        }
        console.log(
          `[Main] Relaying startGoalPlan to AgentBot worker for goal: "${goal}"`
        );
        // TODO: Store association between socket.id and this goal request
        // so progress can be sent back specifically to this client.
        targetWorker.postMessage({
          type: 'startGoalPlan',
          payload: { goal, mode },
        });
      } catch (err: any) {
        console.error('[Main] Error starting goal plan:', err);
        socket.emit(
          'goalPlanError',
          err.message || 'Unknown error starting goal plan'
        );
      }
    }
  );
});

// --- Start Server ---
const PORT = process.env.PORT || 3000;
server.listen(PORT, () => {
  console.log(`Server running on http://localhost:${PORT}`);
  console.log(`Dashboard: http://localhost:${PORT} \n`);
  const runStartDateAndTime = new Date(Date.now());
  console.log('Run Started at:', runStartDateAndTime.toLocaleString(), '\n');
  // Initialize workers after server starts listening
  initializeWorkers();
});

// Handle graceful shutdown
process.on('SIGINT', async () => {
  // Make the handler async
  console.log('SIGINT received. Shutting down workers...');

  const exitPromises: Promise<void>[] = []; // Array to hold promises

  workers.forEach((worker, username) => {
    console.log(`[Main] Terminating worker ${username}...`);
    // Create a promise that resolves when the worker exits
    const exitPromise = new Promise<void>((resolve, reject) => {
      worker.once('exit', (code) => {
        console.log(`[Main] Worker ${username} exited with code ${code}`);
        if (code !== 0) {
          console.warn(`[Main] Worker ${username} exited abnormally.`);
          // Decide if abnormal exit should prevent clean shutdown (reject)
          // or just be logged (resolve)
        }
        resolve(); // Resolve the promise when exit event occurs
      });
      worker.once('error', (err) => {
        console.error(`[Main] Error during termination for ${username}:`, err);
        reject(err); // Reject the promise on error
      });

      // Initiate termination *after* setting up listeners
      worker.terminate();
    });
    exitPromises.push(exitPromise);
  });

  // Keep the overall timeout as a failsafe for the *entire* shutdown
  const shutdownTimeout = setTimeout(() => {
    console.error('Shutdown timed out. Forcing exit.');
    process.exit(1);
  }, 10000); // Increased timeout (e.g., 10 seconds)

  try {
    // Wait for all workers to emit 'exit'
    await Promise.all(exitPromises);
    console.log('[Main] All workers have exited.');
    process.exit(0);
  } catch (error) {
    console.error('[Main] Error during worker termination:', error);
    clearTimeout(shutdownTimeout); // Clear the failsafe timeout
    process.exit(1); // Exit with error if waiting failed
  }
});
